{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the function for calculating Cohen's kappa score \n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for processing the textdocument containing the categorization done by ChatGPT UiO and Llama3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(filename):\n",
    "    category_list = []\n",
    "    with open(filename, 'r') as infile:\n",
    "        for lines in infile:\n",
    "            # splits each line in the textfile\n",
    "            line_split = lines.split('\\n')\n",
    "\n",
    "            #checks if there's multiple categories in one line\n",
    "            if len(line_split[0]) > 20:\n",
    "                comma_split = lines.split(',')        # splits by comma\n",
    "                for i in range(len(comma_split) - 1):\n",
    "                    category_list.append(comma_split[i].strip(' '))     # removes whitespace and adds the line to the list\n",
    "            else:\n",
    "                # removes whitespace and comma and adds it to the list\n",
    "                caps_remove = line_split[0].lower()\n",
    "                category_list.append((caps_remove.strip(',')).strip(' '))\n",
    "    \n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for processing the categorization done by the centroid method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of numbers to category\n",
    "number_to_category = {\n",
    "    '0.0': 'politics',\n",
    "    '1.0': 'business',\n",
    "    '2.0': 'health',\n",
    "    '3.0': 'sports',\n",
    "    '4.0': 'tech',\n",
    "    '5.0': 'entertainment'\n",
    "}\n",
    "\n",
    "def embed_converter(filename):\n",
    "    '''\n",
    "    Reads the file and for every line, splits the value and newline. \n",
    "    Then assigns a category to each number using the dictionary, and if no mapping exists,\n",
    "    the number is categorized as 'unknown'.\n",
    "    '''\n",
    "    category_list = []\n",
    "    with open(filename, 'r') as infile:\n",
    "        for lines in infile:\n",
    "            l_split = lines.split('\\n')\n",
    "            category_list.append(number_to_category.get(l_split[0], 'unknown'))\n",
    "\n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating instances for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = text_processing('newsdataset_ground_truth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1 = text_processing('output_gpt.txt')\n",
    "run_2 = text_processing('newsdataset_output_Anna.txt')\n",
    "run_3 = text_processing('newsDataSetGPTcoding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_run = embed_converter('embed_news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_run1 = text_processing('llama3_news_classification_output_run1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa score for ChatGPT UiO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs through each of the different runs in ChatGPT UiO and compares the different runs to the ground truth and each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ: Ground truth and Run 1 = 0.8968636487125565\n",
      "κ: Ground truth and Run 2 = 0.7811913027230619\n",
      "κ: Ground truth and Run 3 = 0.8942869655828564\n",
      "κ: Run 1 and Run 2 = 0.8183344707886739\n",
      "κ: Run 1 and Run 3 = 0.9497358619545713\n",
      "κ: Run 2 and Run 3 = 0.8231740262291861\n"
     ]
    }
   ],
   "source": [
    "run_list = [ground_truth, run_1, run_2, run_3]\n",
    "run_name = ['Ground truth', 'Run 1', 'Run 2', 'Run 3']\n",
    "\n",
    "for i in range(0,len(run_list)):\n",
    "    for j in range(i+1, len(run_list)):\n",
    "        print(f'{chr(954)}: {run_name[i]} and {run_name[j]} = {cohen_kappa_score(run_list[i],run_list[j])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa Score for Centroid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ: Ground truth and Centroid Method = 0.775840597758406\n"
     ]
    }
   ],
   "source": [
    "print(f'{chr(954)}: Ground truth and Centroid Method = {cohen_kappa_score(ground_truth, embed_run)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluded list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_t_c = ground_truth.copy()\n",
    "embed_ex = embed_converter('embed_news_excluded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(embed_ex):\n",
    "    if embed_ex[i] == 'unknown':\n",
    "        embed_ex.pop(i)\n",
    "        ground_t_c.pop(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212882389320273"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(ground_t_c, embed_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa Score for Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ: Ground truth and Run 1 = 0.8748354085622594\n"
     ]
    }
   ],
   "source": [
    "run_list = [ground_truth, llama_run1]\n",
    "run_name = ['Ground truth', 'Run 1']\n",
    "\n",
    "for i in range(0,len(run_list)):\n",
    "    for j in range(i+1, len(run_list)):\n",
    "        print(f'{chr(954)}: {run_name[i]} and {run_name[j]} = {cohen_kappa_score(run_list[i],run_list[j])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
