{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the function for calculating Cohen's kappa score \n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(filename):\n",
    "    ''' \n",
    "    Opens the files created by prompting Llama3 through Powershell, and finds all instances of brackets, [],\n",
    "    and adds these to a list.\n",
    "    Then runs through each element in the list, which is now a string of numbers, and splits by comma\n",
    "    and removes whitespace.\n",
    "    `filename`: a textfile with output from prompting Llama3\n",
    "    '''\n",
    "    with open(filename, 'r', encoding='utf-16le') as infile:\n",
    "        text = infile.read()\n",
    "    \n",
    "    bracket_list = re.findall(r'\\[(.*?)\\]', text)\n",
    "\n",
    "    split_num_values = np.zeros((len(bracket_list),11))\n",
    "    for i in range(len(bracket_list)):\n",
    "        comma_sp = bracket_list[i].split(',')       # splits by comma\n",
    "        x = np.zeros(11)\n",
    "        for j in range(len(comma_sp)):\n",
    "            x[j] = comma_sp[j].strip(' ')\n",
    "        split_num_values[i] = x\n",
    "\n",
    "    return split_num_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating instances for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the pickle-file previosly created in as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting this dataframe to an array to compare with the other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df.iloc[0:, 2:-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_1 = text_processing('llama_output/output_drexl_1.txt')\n",
    "run_2 = text_processing(r'C:\\Users\\maria\\OneDrive - Universitetet i Oslo\\VÅR2024\\Textembedding\\Drexl\\llama_output\\output_drexl_2.txt')\n",
    "run_3 = text_processing(r'C:\\Users\\maria\\OneDrive - Universitetet i Oslo\\VÅR2024\\Textembedding\\Drexl\\llama_output\\output_drexl_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa score for Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cohen(y1, y2):\n",
    "    ''' \n",
    "    Computes Cohen's Kappa Score for a nested array by row and by column(category).\n",
    "    `y1`: nested array\n",
    "    `y2`: nested array\n",
    "    '''\n",
    "    # by row\n",
    "    cohen_by_row = np.zeros(len(y1))\n",
    "    for i in range(len(y1)):\n",
    "        cohen_by_row[i] = cohen_kappa_score(y1[i],y2[i])\n",
    "\n",
    "    # by column/category\n",
    "    cohen_by_column = np.zeros(len(y1[0]))\n",
    "    for i in range(len(y1[0])):\n",
    "        y1_col = y1[:,i]\n",
    "        y2_col = y2[:,i]\n",
    "        cohen_by_column[i] = cohen_kappa_score(y1_col,y2_col)\n",
    "        \n",
    "    return cohen_by_row, cohen_by_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26666667 0.09836066 0.81967213 ... 0.37735849 0.21428571 0.21428571]\n",
      "0.338216959184075\n",
      "1.0 -0.8333333333333335\n",
      "0.10616291536361791\n",
      "0.32582651114299754\n",
      "b\n",
      "[0.2897278  0.19275779 0.09860936 0.40400533 0.15456178 0.13627841\n",
      " 0.1160208  0.12020517 0.10966349 0.13010518 0.12344765]\n",
      "0.1704893419990963\n",
      "0.08988534350428326\n"
     ]
    }
   ],
   "source": [
    "a, b = nested_cohen(run_2, run_3)\n",
    "print(a)\n",
    "print(np.mean(a))\n",
    "print(np.max(a), np.min(a))\n",
    "print(np.var(a))\n",
    "print(np.std(a))\n",
    "\n",
    "print('b')\n",
    "print(b)\n",
    "print(np.mean(b))\n",
    "print(np.std(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22222222  0.47619048 -0.51724138 ...  0.42105263  0.02941176\n",
      "  0.29787234]\n",
      "0.13801863874833842\n",
      "1.0 -0.7741935483870968\n",
      "0.0799816678412158\n",
      "b\n",
      "[0.00962143 0.10594643 0.02325453 0.33332418 0.07743069 0.01397804\n",
      " 0.05299897 0.07762211 0.0439125  0.1083958  0.06303668]\n",
      "0.08268375910752898\n"
     ]
    }
   ],
   "source": [
    "a, b = nested_cohen(ground_truth, run_2)\n",
    "print(a)\n",
    "print(np.mean(a))\n",
    "print(np.max(a), np.min(a))\n",
    "print(np.var(a))\n",
    "\n",
    "print('b')\n",
    "print(b)\n",
    "print(np.mean(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa Score for Centroid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ: Ground truth and Centroid Method = 0.775840597758406\n"
     ]
    }
   ],
   "source": [
    "print(f'{chr(954)}: Ground truth and Centroid Method = {cohen_kappa_score(ground_truth, embed_run)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluded list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'embed_news_excluded.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ground_t_c \u001b[38;5;241m=\u001b[39m ground_truth\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 2\u001b[0m embed_ex \u001b[38;5;241m=\u001b[39m embed_converter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed_news_excluded.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m, in \u001b[0;36membed_converter\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mReads the file and for every line, splits the value and newline. \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mThen assigns a category to each number using the dictionary, and if no mapping exists,\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mthe number is categorized as 'unknown'.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     17\u001b[0m category_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lines \u001b[38;5;129;01min\u001b[39;00m infile:\n\u001b[0;32m     20\u001b[0m         l_split \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maria\\.conda\\envs\\embed\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embed_news_excluded.csv'"
     ]
    }
   ],
   "source": [
    "ground_t_c = ground_truth.copy()\n",
    "embed_ex = embed_converter('embed_news_excluded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes the \"unknown\" values, ie. the values where the greatest value in the distribution from the centroid method was less than 0.50, from both the ground truth and the list from the embeddings to get comparable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(embed_ex):\n",
    "    if embed_ex[i] == 'unknown':\n",
    "        embed_ex.pop(i)\n",
    "        ground_t_c.pop(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212882389320273"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(ground_t_c, embed_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa Score for Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ: Ground truth and Run 1 = 0.8748354085622594\n",
      "κ: Ground truth and Run 2 = 0.869899822863605\n",
      "κ: Ground truth and Run 3 = 0.8650661176023748\n",
      "κ: Run 1 and Run 2 = 0.9550195664885774\n",
      "κ: Run 1 and Run 3 = 0.9525706697021438\n",
      "κ: Run 2 and Run 3 = 0.9650587013816788\n"
     ]
    }
   ],
   "source": [
    "run_list = [ground_truth, llama_run1, llama_run2, llama_run3]\n",
    "run_name = ['Ground truth', 'Run 1', 'Run 2', 'Run 3']\n",
    "\n",
    "for i in range(0,len(run_list)):\n",
    "    for j in range(i+1, len(run_list)):\n",
    "        print(f'{chr(954)}: {run_name[i]} and {run_name[j]} = {cohen_kappa_score(run_list[i],run_list[j])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
